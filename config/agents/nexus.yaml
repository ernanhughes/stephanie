nexus:
  name: nexus
  enabled: true
  save_prompt: false
  save_context: false
  skip_if_completed: false

  # ------------------------------------------------------------------
  # Core / Model
  # ------------------------------------------------------------------
  model:
    name: ollama/qwen3
    api_base: http://localhost:11434
    api_key: null

  embeddings:
    backend: ${embeddings.backend}   # e.g. "hnet", stays in sync with global

  paths:
    vpm_out: "./runs/vpm/nexus"
    cache_dir: ".vision_scorer_cache"
    artifacts: "./runs/nexus_artifacts"
    prompts: "${paths.prompts}"      # for analyze helper

  # ------------------------------------------------------------------
  # Data loading → Scorables → Graph
  # ------------------------------------------------------------------
  loader:
    role_filter: "assistant"     # null for all roles
    limit: 5000
    min_text_len: 80

  indexer:
    batch_size: 128
    normalize_l2: true
    persist: true
    faiss:
      use_gpu: true
      nprobe: 32
    knn:
      k: 12
      edge_threshold: 0.35
    cap:
      max_nodes: 50000
      max_edges_per_node: 32

  # ------------------------------------------------------------------
  # Path search over the Nexus graph
  # ------------------------------------------------------------------
  pathfinder:
    beam_width: 6
    max_path_len: 24
    min_path_len: 3
    backtrack: true
    start_strategy: "nearest_to_goal"   # "nearest_to_goal" | "seed_node"
    weights:
      alpha_text: 0.55
      beta_goal: 0.20
      gamma_stability: 0.15
      zeta_agreement: 0.05
      delta_domain: 0.03
      epsilon_entity: 0.02
    penalties:
      revisit: 0.10
      long_hop: 0.05
    stops:
      max_total_cost: 9999
      target_hit_threshold: 0.82

  # Optional external signals Nexus can consume if present
  signals:
    use_hallucination: true
    use_uncertainty: true
    use_agreement: true

  # ------------------------------------------------------------------
  # Text scoring (Scorable → vector)
  # Used by NexusMetricsWorkerInline
  # ------------------------------------------------------------------
  scorers: 
    - sicql
    - hrm
    - tiny
    - ebt
    - svm
    - mrq
    - knowledge
  dimensions:
    - alignment
    - clarity
    - relevance
    - coverage
    - faithfulness
    - novelty
    - implementability
  persist: false


  graph:
    knn_k: 12
    sim_threshold: 0.35
    max_edges_per_node: 24
    add_temporal: true
    add_mst_backbone: true

    edge_caps:
      knn_blend: 250000
      temporal_next: 250000
      backbone_mst: 100000

    edge_weights:
      embed: 0.50
      metrics: 0.25
      lexical: 0.10
      domains: 0.08
      entities: 0.05
      agreement: 0.02
      stability: 0.00

  pulse:
    enabled: true
    k: 25                 # neighbors per pulse
    depth: 2              # subgraph ego radius
    min_sim: 0.35
    sse_subject: "nexus.pulse"      # UI SSE bus subject
    expand_workers: 3
    fanout_limit: 200              # safety valve

  goals:
    # “identity” goals (raise/lower thresholds per your taste)
    - id: self_improvement
      priority: 0.95
      activation_threshold: 0.70
      keywords: ["improve", "optimize", "learn", "train", "self-play", "policy"]
    - id: knowledge_discovery
      priority: 0.90
      activation_threshold: 0.65
      keywords: ["paper", "result", "proof", "novel", "SOTA", "benchmark"]
    - id: system_preservation
      priority: 0.85
      activation_threshold: 0.60
      keywords: ["error", "outage", "latency", "risk", "hallucination", "health"]

  # ------------------------------------------------------------------
  # Visual scoring & rendering (ZeroModel)
  # Used by NexusVPMWorkerInline + ZeroModelService
  # ------------------------------------------------------------------
  vpm:
    dims_for_score:
      - clarity
      - coherence
      - complexity
      - alignment
      - coverage
    rollout_steps: 0                  # 0 = score only (no extra visual ops)
    rollout_strategy: "consensus-walk"
    save_channels: false

  zero_model:
    fps: 8
    max_frames: 1024
    output_dir: "./data/runs/"
    timeline_scale_mode: "robust01"
    pipeline:
      - { stage: "normalize",           params: {} }
      - { stage: "feature_engineering", params: {} }
      - { stage: "organization",        params: { strategy: "spatial" } }
    epistemic_field:
      enabled: true
      alpha: 0.97
      Kc: 40
      Kr: 100
      fps: 8
      cmap: "seismic"
      aggregate: false

  # Optional viewer/filmstrip defaults
  filmstrip:
    rows: 2
    cols: 12
    dpi: 200
    border_px: 2
    border_color: 255
    label_on: false
    label_pos: tl
    label_color: 255
    label_bg: 0

  vpm_viz:
    raw_render: bar
    progress_render: bar
    bar_height: 12
    grid_side: 32
    fixed_scale: true
    dimensions:
      - clarity
      - coherence
      - complexity
      - alignment
      - coverage
    output_dir: "./runs/vpm/nexus/viz"
    tl_fracs: [0.25, 0.16, 0.36, 0.09]
    delta: 0.02

  # ------------------------------------------------------------------
  # Agent flow wiring
  # ------------------------------------------------------------------
  flow:
    batch_size: 16
    max_items: 200
    stop_on_error: false
    progress_every: 10

  # ------------------------------------------------------------------
  # Telemetry / Bus subjects (event versions drop in without code changes)
  # ------------------------------------------------------------------
  telemetry:
    enabled: true
    subject_root: nexus
    sample: 1.0
    persist: true
    extra:
      app: stephanie
      component: nexus

  bus:
    vpm:
      request: "arena.nexus.vpm.request"
      ready:   "arena.nexus.vpm.ready"
    metrics:
      request: "arena.nexus.metrics.request"
      ready:   "arena.nexus.metrics.ready"

  # ------------------------------------------------------------------
  # Safety hooks for Daimon (soft guards)
  # ------------------------------------------------------------------
  guards:
    enable_risk_checks: false
    overlap_min: 0.05
    delta_mass_min: -0.10

  # ------------------------------------------------------------------
  # Helper sub-agents (same file, separate runners can reference these keys)
  # ------------------------------------------------------------------
  annotate:
    seed_config: "config/domain/seeds.yaml"
    goal_config: "config/domain/goal_prompt.yaml"
    max_domains_per_source: 3
    min_confidence: 0.10
    only_missing: true
    force: false
    progress: true
    filter_role: true
    scorable_role: "assistant"

  analyze:
    limit: 10000
    force_rescore: false
    prompt_dir: "./prompts/chat_analyze"
    dimensions:
      - reasoning
      - knowledge
      - clarity
      - faithfulness
      - coverage
    model:
      name: ollama/qwen3
      api_base: http://localhost:11434
      api_key: null

  # ------------------------------------------------------------------
  # Seeds / Dev switches
  # ------------------------------------------------------------------
  seeds:
    - "Summarize this week’s progress succinctly."
    - "List three risks in our current reasoning stack."
    - "Explain the role of VPMs in one paragraph."

  dev:
    dry_run: false
    log_level: INFO
    save_step_json: true

  vpm_out: "./runs/nexus_vpm"
  rollout_steps: 0
  rollout_strategy: "consensus-walk"
  target_type: "conversation_turn"

  graph_build:
    embed_key: "global"
    knn_k: 12
    sim_threshold: 0.35

  ab_compare:
    enabled: true
    top_k: 10
    seed: 0
    target_source: "goal"     # "goal" | "text"
    target_text: ""           # used if target_source == "text"
    prefer_item_embedding: true   # use embeddings.global if available

  processor:
    _target_: stephanie.scoring.metrics.scorable_processor.ScorableProcessor

    # Inline is simplest; you can flip to async/rpc later
    offload_mode: inline
    enable_manifest: false
    enable_item_progress: false

    # IMPORTANT: for cohort building we want fresh scores on each row so that
    # metrics_columns/values are populated even if source scorables were bare.
    attach_scores: true
    require_metrics_for_vpm: false

    # ---- per-row features (run on each scorable) ----
    features:
      - metrics
      - frontier_lens  # light per-row summary; the heavy lift happens in visicalc_group

    feature_configs:
      metrics:
        enabled: true
        # Keep all four so we don't accidentally drop Tiny again
        scorers: ["hrm", "sicql", "tiny", "ebt"]
        dimensions: [coverage, reasoning, knowledge, clarity, faithfulness]
        persist: false          # compute on the fly; DB persistence optional
        attach_scores: true

      frontier_lens:
        enabled: true
        # Preferred metric ordering (optional)
        metric_keys:
          - "HRM.coverage.score"
          - "sicql.coverage.score"
          - "tiny.coverage.score"
          - "svm.coverage.score"
        frontier_metric: "HRM.aggregate"
        row_region_splits: 4
        frontier_low: 0.25
        frontier_high: 0.75

        # Case-insensitive mapping (MetricMapper: ignore_case=True by default in your code)
        metric_mapping:
          include: ["HRM.*", "sicql.*", "tiny.*", "ebt Hello.*"]
          exclude: ["*.raw", "*.debug"]

        # Optional tiny previews (heavy VPM happens in group feature)
        vpm_png:
          enabled: true
          mode: "L"
          per_metric_normalize: true
          target_file: "visicalc_targeted_vpm.png"
          baseline_file: "visicalc_baseline_vpm.png"

        # Row-level hints only (cohort selection done in group step)
        top_k_metrics: 50
        min_effect: 0.25
        importance_filter:
          enabled: true
          path: "config/core_metrics.json"
          top_k: 100
          min_effect: 0.1

    # ---- group features (run once after all rows are built) ----
    group_feature_configs:
      metric_filter:
        enabled: true
        top_k: 100
        normalize: true
        include: ["HRM.*", "sicql.*", "Tiny.*"]
        exclude: ["*.raw", "*.debug"]
        alias_strip: true
        short_circuit_if_locked: true
        include_visicalc_core: false
        visicalc_core_names:
        always_include:
          - "tiny.aggregate"
          - "svm.aggregate"
          - "Tiny.faithfulness.attr.scm.aggregate01"

      # 2) Cohort VisiCalc (heavy batch) + feature lock
      frontier_lens_group:
        enabled: true
        # Runs cohort analysis on the filtered metric matrix; attaches per-row
        # visicalc_features / visicalc_feature_names / visicalc_report / visicalc_quality
        episode_id: "critic:${hydra:runtime.run_dir}"  # any unique tag is fine
        frontier_metric: "Tiny.faithfulness.attr.scm.aggregate01"
        row_region_splits: 4
        frontier_low: 0.25
        frontier_high: 0.75
        per_metric_normalize: true
        metric_mapping:
          include: ["HRM.*", "sicql.*", "tiny.*", "svm.*"]
          exclude: ["*.raw", "*.debug"]
        # files written under runs/visicalc/<run_id> by your tool
        out_dir: "runs/critic/scorer"
        json_file: "visicalc_report.json"
        csv_file: "visicalc_report.csv"

