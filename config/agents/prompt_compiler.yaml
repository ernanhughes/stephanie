# config/agents/prompt_compiler.yaml
prompt_compiler:
  name: prompt_compiler
  enabled: true
  save_context: false
  skip_if_completed: false

  ats_N_init: 6            # parallel initial drafts
  ats_max_iter: 120        # total iterations
  ats_time_limit: 1200     # 20 minutes wallclock
  ats_patience: 30         # early stop if no improvement
  ats_H_greedy: 0.55       # exploit best node sometimes
  ats_C_ucb: 1.3           # explore/exploit balance
  random_seed: 123


  model:
    name: ollama_chat/qwen3
    api_base: http://localhost:11434
    api_key: null

  judge: mrq
  judge_prompt_file: evaluator.txt
  judge_model:
    name: ollama_chat/qwen3
    api_base: http://localhost:11434
    api_key: null

  strategy: dspy_compilation

  # Required keys for the agent ot effectively process the context
  required_keys: ["goal", "hypotheses"]   # add nodes
  # Key that it will iterate over ot generate reflections
  input_key: "prompts"
  # Key that it store the results of those reflections
  output_key: "tuned_prompts"  # change

  save_prompt: true
  prompt_mode: file
  prompt_file: compile_prompt.txt

  # A set of keys that will tune the prompts operation
  preferences:
    - goal_consistency
    - factual
    - reliable_source
    - simplicity