# configs/agents/step_processor.yaml

step_processor:
  name: step_processor

  save_prompt: true
  save_context: false
  skip_if_completed: false
  use_memory_for_fast_prompts: false

  evaluator: llm         #(mrq or llm)  may not be enough items fo mrq
  evaluator_prompt_file: evaluation.txt
  evaluator_model:
    name: ollama/phi3
    api_base: http://localhost:11434
    api_key: null

  analysis_model:
    name: ollama/llama3.2
    api_base: http://localhost:11434
    api_key: null

  model:
    name: ollama/qwen3
    api_base: http://localhost:11434
    api_key: null

  input_key: step_plan
  output_key: step_outputs
  prompt_mode: file
  prompt_file: step_processor.txt


  remove_think: false # we require "thinking" part of the prompt

  device: cpu # How many epochs to wait after no improvement
  limit: 1000 # max training data
  epochs: 20  # how much to train
  patience: 3  # How many epochs to wait after no improvement
  min_delta: 0.0001  # Minimum change in loss to qualify as improvement
  log_results: true # save results to database
  save_improved: true # save improved prompts and hypotheses
