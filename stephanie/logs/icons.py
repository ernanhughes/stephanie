# stephanie/logs/icons.py
def get_event_icon(event_type: str) -> str:
    """Get the icon associated with a specific event type."""
    return EVENT_ICONS.get(event_type, "â“")  # Default: question mark

# ========================
# SYSTEM & INITIALIZATION
# ========================
SYSTEM_INIT = {
    "ContextManagerInitialized": "âš™ï¸",  # Context manager initialized
    "UncertaintyEstimated": "ğŸ”",  # Uncertainty estimation
    "EBTEnergyCalculated": "âš¡",  # EBT energy calculation
    "ScoringPolicyCompleted": "âœ…",  # Scoring policy completed
    "AllEBTModelsLoaded": "ğŸ“¦âœ…",  # All EBT models loaded
    "SupervisorInit": "ğŸ‘¨â€ğŸ«",  # Supervisor initialization
    "DocumentLLMInferenceCompleted": "ğŸ“„âœ…",  # Document LLM inference completed
    "DocumentEmbeddingsBackfilled": "ğŸ“„ğŸŒ±",  # Document embeddings backfilled
    "AgentInitialized": "ğŸ¤–",  # Agent initialization
    "ContextLoaded": "ğŸ“‚",  # Context loaded
    "ContextSaved": "ğŸ’¾",  # Context saved
    "SupervisorComponentsRegistered": "ğŸ‘¨â€ğŸ«",  # Supervisor registration
    "DomainClassifierInit": "ğŸ·ï¸ğŸ§ ",  # Domain classifier init
    "DomainConfigLoaded": "ğŸ·ï¸ğŸ“‹",  # Domain config loaded
    "SeedEmbeddingsPrepared": "ğŸŒ±ğŸ§¬",  # Seed embeddings prepared
    "KnowledgeDBLoaded": "ğŸ“šâœ…",  # Knowledge database loaded
}

# =================
# AGENT OPERATIONS
# =================
AGENT_EVENTS = {
    "AgentInitialized": "ğŸ¤–",  # Agent initialization
    "AgentRunStarted": "ğŸ¤–â–¶ï¸",  # Agent run started
    "AgentRunCompleted": "ğŸ¤–â¹ï¸",  # Agent run completed
    "AgentRanSuccessfully": "ğŸ¤–âœ…",  # Agent succeeded
    "GILDTrainerAgentInitialized": "ğŸ“ŠğŸ¤–",  # GILD trainer agent initialized
    "MRQInferenceAgentInitialized": "ğŸ“ŠğŸ¤–",  # MRQ inference agent initialized
    "MRQTrainerAgentInitialized": "ğŸ“ŠğŸ¤–",  # MRQ trainer agent initialized
    "DocumentMRQInferenceAgentInitialized": "ğŸ“ŠğŸ¤–",  # Document MRQ inference agent initialized
    "DocumentEBTInferenceAgentInitialized": "ğŸ§ ğŸš¦",  # Inference agent initialized
    "EpistemicPlanExecutorAgentInitialized": "ğŸª¸ğŸ¤–",  # Epistemic plan executor agent initialized
}

# =================
# KNOWLEDGE STORAGE
# =================
KNOWLEDGE_OPS = {
    "GenerationStart": "ğŸ§‘â€ğŸ§’â€ğŸ§’â–¶ï¸",  # Knowledge generation started
    "GoalContextOverride": "ğŸ¯ğŸ”„",  # Goal context override
    "MgrScoreParseError": "ğŸ“ŠâŒ",  # Scoring parse error
    "SymbolicRulesFound": "ğŸ§©ğŸ”",  # Symbolic rules found
    "MRQTrainingDataLoaded": "ğŸ“ŠğŸ“¥",  # MRQ training data loaded
    "DuplicateSymbolicRuleSkipped": "ğŸš«ğŸ§©",  # Duplicate symbolic rule skipped
    "EvolvedParsedHypotheses": "ğŸŒ±ğŸ’¡",  # Evolved hypotheses parsed
    "EvolutionCompleted": "ğŸŒ±âœ…",  # Evolution completed
    "ExecutionStepStored": "ğŸ“¥âœ…",  # Execution step stored
    "MetaReviewInput": "ğŸ“ğŸ“‹",  # Meta-review input
    "RawMetaReviewOutput": "ğŸ“ğŸ“„",  # Raw meta-review output
    "NotEnoughHypothesesForRanking": "âŒğŸ’¡",  # Not enough hypotheses for ranking
    "PromptLookup": "ğŸ”ğŸ“",  # Prompt lookup
    "RubricClassified": "ğŸ·ï¸ğŸ“„",  # Rubric classified
    "PlanTraceStored": "ğŸ“„ğŸ’¾",  # Plan trace stored
    "PromptGenerated": "ğŸ“âœ¨",  # Prompt generated
    "PatternStatsStored": "ğŸ“ŠğŸ’¾",  # Pattern stats stored
    "LLMJudgeResults": "ğŸ“âš–ï¸",  # LLM judge results
    "RubricPatternsStored": "ğŸ“ŠğŸ’¾",  # Rubric patterns stored
    "EBTBufferLoaded": "ğŸ§ªğŸ“¦",  # EBT buffer loaded
    "EBTInferenceCompleted": "ğŸ§ªâœ…",  # EBT inference complete
    "MemCubeSaved": "ğŸ’¾ğŸ“¦âœ…",  # MemCube saved
    "DocumentRefinedWithEBT": "ğŸ“„ğŸ”„",  # Document refined with EBT
    "EBTExampleAdded": "ğŸ§ªâ•",  # EBT example added
    "MRQScoresCalculated": "ğŸ“Šâœ…",  # MRQ scores calculated
    "ScoringEvent": "ğŸ“Š",  # Scoring event
    "TripletsRetrievedByDomain": "ğŸ”—ğŸ·ï¸",  # Triplets retrieved by domain
    "DomainAssigned": "ğŸ·ï¸âœ…",  # Domain assigned
    "MRQTunedScore": "ğŸ§ ğŸ“Š",  # MRQ tuned score
    "CartridgeCreated": "ğŸ’¾ğŸ“¦",  # Cartridge created
    "CartridgeAlreadyExists": "ğŸ’¾âœ…",  # Cartridge exists check
    "TriplesAlreadyExist": "ğŸ”—âœ…",  # Triples exist check
    "CartridgeDomainInserted": "ğŸ’¾ğŸ·ï¸",  # Cartridge domain added
    "TripleInserted": "ğŸ”—",  # Triple inserted
    "SectionInserted": "ğŸ“‚â•",  # Section inserted
    "TripletScored": "ğŸ”—ğŸ“Š",  # Triplet scored
    "SectionDomainInserted": "ğŸ“‚ğŸ·ï¸",  # Section domain added
    "SectionDomainUpserted": "ğŸ“‚ğŸ”„",  # Section domain updated
    "DocumentAlreadyExists": "ğŸ“„âœ…",  # Document exists check
    "DomainUpserted": "ğŸ·ï¸ğŸ”„",  # Domain updated
    "ContextYAMLDumpSaved": "ğŸ“„ğŸ’¾",  # YAML context saved
    "CartridgeProcessingStarted": "ğŸ’¾â–¶ï¸",  # Cartridge processing started
    "CartridgeDocumentProcessingStarted": "ğŸ’¾ğŸ“„â–¶ï¸",  # Document processing started
    "CartridgeBuilt": "ğŸ’¾âœ…",  # Cartridge built
    "TripletsExtractionCompleted": "ğŸ",  # Triplets extracted
    "DatabaseHypothesesMatched": "ğŸ“Šâœ…",  # Hypotheses matched in DB
    "TripletsInserted": "ğŸ”—ğŸ’¾",  # Triplets inserted
    "TheoremExtracted": "ğŸ“œâœ…",  # Theorem extracted
    "TheoremsExtractionCompleted": "ğŸ",  # Theorems extracted
    "DocumentProfiled": "ğŸ“„ğŸ“‹",  # Document profiled
    "MaxSectionsReached": "ğŸ“„â­ï¸",  # Max sections reached
    "ItemScored": "ğŸ“Šâœ…",  # Item scored
    "CartridgeScored": "ğŸ’¾ğŸ“Š",  # Cartridge scored
    "DomainAssignmentSkipped": "ğŸ·ï¸â­ï¸",  # Domain assignment skipped
    "CartridgeProcessingCompleted": "ğŸ",  # Cartridge processing completed
    "DocumentAlreadyProfiled": "ğŸ“„âœ…",  # Document already profiled
    "StoreRegistered": "ğŸ›’",  # Store registered
    "PreferencePairBuilder": "ğŸ’¾â–¶ï¸",  # Preference pair builder started
}

# =================
# PIPELINE CONTROL
# =================
PIPELINE_FLOW = {
    "PipelineStageCompleted": "ğŸ–‡ï¸âœ…",  # Pipeline stage completed
    "PipelineStageStarted": "ğŸ–‡ï¸â–¶ï¸",  # Pipeline stage started
    "PipelineSummaryPrinted": "ğŸ–‡ï¸ğŸ“„",  # Pipeline summary printed
    "PipelineStageInserted": "ğŸ–‡ï¸â•",  # Stage inserted
    "PipelineStart": "ğŸ–‡ï¸â–¶ï¸",  # Pipeline started
    "PipelineStageStart": "ğŸ–‡ï¸â©",  # Stage started
    "PipelineStageEnd": "ğŸ–‡ï¸ğŸ”š",  # Stage completed
    "PipelineStageSkipped": "ğŸ–‡ï¸â­ï¸",  # Stage skipped
    "PipelineIterationStart": "ğŸ–‡ï¸ğŸ”„",  # Iteration started
    "PipelineIterationEnd": "ğŸ–‡ï¸ğŸ”š",  # Iteration completed
    "PipelineSuccess": "ğŸ–‡ï¸âœ…",  # Pipeline succeeded
    "PipelineRunInserted": "ğŸ–‡ï¸ğŸ’¾",  # Pipeline run saved
    "PipelineJudgeAgentEnd": "âš–ï¸ğŸ”š",  # Judge agent completed
    "MRQPipelineSuggested": "ğŸ§ ğŸ’¡",  # MRQ pipeline suggested
    "PipelineStageFailed": "ğŸ–‡ï¸âš ï¸",  # Pipeline stage failed
    "PipelineScoreSummary": "ğŸ–‡ï¸ğŸ“Š",  # Pipeline score summary
    "PipelineError": "ğŸ–‡ï¸âŒ",  # Pipeline error
}

# =====================
# SCORING & EVALUATION
# =====================
SCORING = {
    "ScoringPaper": "ğŸ“„âš–ï¸",  # Scoring paper
    "EpistemicPlanExecutorSkipped": "ğŸª¸â­ï¸",  # Epistemic plan executor skipped
    "EpistemicPlanHRMTrainingBatch": "ğŸª¸ğŸ‹ï¸",  # Training batch
    "EpistemicPlanHRMDataLoaderCreated": "ğŸª¸ğŸ“¥",  # Data loader created
    "EpistemicPlanHRMTrainingEpoch": "ğŸª¸ğŸ‹ï¸",  # Training epoch
    "EpistemicPlanHRMModelSaved": "ğŸª¸ğŸ§®ğŸ’¾",  # Model saved
    "EpistemicTraceSaved": "ğŸª¸ğŸ’¾",  # Epistemic trace saved
    "HRMScorerEvaluated": "ğŸ§ âš–ï¸",  # HRM scorer evaluated
    "HRMScorerModelLoaded": "ğŸ§ ğŸ§®ğŸ“¥",  # HRM scorer model loaded
    "HRMScorerMetaLoaded": "ğŸ§ ğŸ“„",  # HRM scorer meta loaded
    "LATS_StepStarted": "ğŸ§ ğŸ”„",  # LATS step started
    "LATS_StepCompleted": "ğŸ§ âœ…",  # LATS step completed
    "LargeDataContextComponentDumped": "ğŸ“‚ğŸ’¾",  # Large data context dumped
    "EpistemicPlanExecutorStarted": "ğŸª¸ğŸ“„",  # Epistemic plan executor started
    "EpistemicPlanExecutorCompleted": "ğŸª¸âœ…",  # Epistemic plan executor completed
    "PolicyLogits": "ğŸ“Šâš–ï¸",  # Policy logits computed
    "DocumentScoresAlreadyExist": "ğŸ“„âœ…",  # Document scores already exist
    "LLMJudgeScorerDimension": "ğŸ“ğŸ“Š",  # LLM judge scoring dimension
    "DocumentScored": "ğŸ“Šâœ…",  # Document scored
    "HypothesisScored": "ğŸ’¡ğŸ“Š",  # Hypothesis scored
    "ScoreComputed": "ğŸ§®âœ…",  # Score computed
    "ScoreParsed": "ğŸ“ğŸ“Š",  # Score parsed
    "ScoreSaved": "ğŸ’¾ğŸ“Š",  # Score saved
    "ScoreSavedToMemory": "ğŸ§ ğŸ’¾",  # Score saved to memory
    "ScoreSkipped": "â­ï¸ğŸ“Š",  # Scoring skipped
    "ScoreDelta": "ğŸ“ˆ",  # Score delta
    "ScoreCacheHit": "ğŸ’¾âœ…",  # Score cache hit
    "MRQScoreBoundsUpdated": "ğŸ“ˆğŸ”„",  # MRQ bounds updated
    "MRQDimensionEvaluated": "ğŸ“ğŸ§ ",  # Dimension evaluated
    "CorDimensionEvaluated": "ğŸ“âœ…",  # COR dimension evaluated
    "MRQScoringComplete": "ğŸ“Šâœ…",  # MRQ scoring complete
    "MRQScoreComputed": "ğŸ“âœ…",  # MRQ score computed
    "ReportGenerated": "ğŸ“„âœ…",  # Report generated
    "MRQScoringFinished": "ğŸ“ŠğŸ",  # MRQ scoring finished
    "MRQScoringStarted": "ğŸ“Šâ–¶ï¸",  # MRQ scoring started
    "AllMRQModelsLoaded": "ğŸ“ŠğŸ§®âœ…",  # All MRQ models loaded
    "LoadingModelPaths": "ğŸ“‚ğŸ§®ğŸ”„",  # Model paths loading
    "DocumentModelSaved": "ğŸ“„ğŸ’¾",  # Document model saved
    "ModelSaved": "ğŸ’¾ğŸ§®âœ…",  # Model saved
    "EncoderSaved": "ğŸ“„ğŸ’¾",  # Encoder saved
    "MRQInferenceCompleted": "ğŸ“Šâœ…",  # MRQ inference completed
    "SVMScoringFinished": "ğŸ“ŠğŸ",  # SVM scoring finished
    "SVMScoringStarted": "ğŸ“Šâ–¶ï¸",  # SVM scoring started
    "SVMScoreComputed": "ğŸ“Šâœ…",  # SVM score computed
    "PolicyAnalysis": "ğŸ“ŠğŸ”",  # Policy analysis
    "NoSICQLDataFound": "ğŸš«ğŸ“Š",  # No SI-CQL data found
    "DimensionEvaluated": "ğŸ“âœ…",  # Dimension evaluated
}

# =====================
# REASONING & ANALYSIS
# =====================
REASONING = {
    "PlanTraceMonitorDisabled": "ğŸ“„ğŸ”§",  # Plan trace monitoring disabled
    "PlanTraceSavedToFile": "ğŸ“„ğŸ’¾",  # Plan trace saved to file
    "PlanTraceCompleted": "ğŸ“„âœ…",  # Plan trace completed
    "MARSAnalysisCompleted": "ğŸ“Šâœ…",  # MARS analysis completed
    "PlanTraceScoringCompleted": "ğŸ“„âœ…",  # Plan trace scoring completed
    "PlanTraceUpdated": "ğŸ“„ğŸ”„",  # Plan trace updated
    "PlanTraceScored": "ğŸ“„âš–ï¸",  # Plan trace scored
    "PlanTraceScoringComplete": "ğŸ“„âœ…",  # Plan trace scoring completed
    "DocumentScoringProgress": "ğŸ“„ğŸ”„",  # Document scoring progress
    "DocumentScoringCompleted": "ğŸ“„âœ…",  # Document scoring completed
    "EpistemicPlanHRMModelInitialized": "ğŸª¸ğŸ§ ",  # Epistemic Plan HRM model initialized
    "EpistemicPlanHRMOptimizerInitialized": "ğŸª¸âš™ï¸",  # Epistemic Plan HRM optimizer initialized
    "EpistemicPlanHRMLossInitialized": "ğŸª¸ğŸ“‰",  # Epistemic Plan HRM loss initialized
    "EpistemicPlanHRMTrainingNoTraces": "ğŸª¸ğŸš«",  # No traces for training
    "EpistemicPlanHRMTrainingStarted": "ğŸª¸ğŸš€",  # Epistemic Plan HRM training started
    "EpistemicPlanHRMTrainingDataPrepared": "ğŸª¸ğŸ“Š",  # Training data prepared

    "KeywordsExtracted": "ğŸ”‘",  # Keywords extracted
    "ProximityAnalysisScored": "ğŸ“ŒğŸ—ºï¸",  # Proximity analysis
    "ProximityGraphComputed": "ğŸ“ŠğŸŒ",  # Proximity graph
    "HypothesisJudged": "âš–ï¸",  # Hypothesis judged
    "SymbolicAgentRulesFound": "ğŸ§©ğŸ”",  # Symbolic rules found
    "SymbolicAgentOverride": "ğŸ§ ğŸ”„",  # Symbolic override
    "RuleApplicationLogged": "ğŸ§¾ğŸ§©",  # Rule application logged
    "RuleApplicationUpdated": "ğŸ”„ğŸ§©",  # Rule application updated
    "RuleApplicationCount": "ğŸ”¢ğŸ§©",  # Rule applications counted
    "RuleApplicationsScored": "ğŸ¯ğŸ§©",  # Rule applications scored
    "NoSymbolicAgentRulesApplied": "ğŸš«ğŸ§©",  # No rules applied
    "SymbolicAgentNewKey": "ğŸ”‘ğŸ§ ",  # New symbolic key
    "SymbolicPipelineSuggestion": "ğŸ’¡ğŸ§©",  # Symbolic pipeline suggestion
}

# =====================
# TRAINING & MODEL OPS
# =====================
TRAINING = {
    "TrainingStarted": "ğŸ‹ï¸â–¶ï¸",  # Training started
    "CalibrationCompleted": "âœ…ğŸ“Š",  # Calibration completed
    "ContrastiveRankerTrainingComplete": "ğŸ“ğŸ“Š",  # Contrastive ranker training completed
    "TrainingEpochsCompleted": "ğŸ‹ï¸âœ…",  # Training epochs completed
    "DimensionTrainingStart": "ğŸ“â–¶ï¸",  # Dimension training started
    "ContrastiveRankerTrainingStarted": "ğŸ“ŠğŸ‹ï¸",  # Contrastive ranker training started I
    "SICQLTrainerInitialized": "ğŸ“ŠğŸ¤–",  # SICQL trainer initialized   
    "SVMTrainingComplete": "ğŸ“ğŸ“Š",  # SVM training completed
    "SVMTrainingCompleted": "ğŸ“ğŸ“Š",  # SVM training completed
    "SVMTrainerInvoked": "ğŸ“ŠğŸ¤–",  # SVM trainer invoked
    "DimensionTrainingStarted": "ğŸ“â–¶ï¸",  # Dimension training started
    "DimensionTrainingComplete": "ğŸ“ğŸ“",  # Dimension training completed
    "TunerMissing": "ğŸ”§ğŸ“„",  # Tuner missing
    "MRQTrainerEpoch": "ğŸ‹ï¸",  # MRQ training epoch
    "MRQTrainerStart": "ğŸš€ğŸ§ ",  # MRQ training started
    "MRQTrainerTrainingComplete": "ğŸ“ğŸ§ ",  # MRQ training completed
    "MRQModelInitializing": "ğŸ§ ğŸ§®âš™ï¸",  # MRQ model initializing
    "TrainingEpoch": "ğŸ‹ï¸",  # Training epoch
    "TrainingComplete": "ğŸ“âœ…",  # Training completed
    "TrainingDataProgress": "ğŸ“ˆğŸ”„",  # Training data progress
    "RegressionTunerFitted": "ğŸ“ˆğŸ”§",  # Regression tuner fitted
    "RegressionTunerTrainSingle": "ğŸ”§â–¶ï¸",  # Tuner training
    "DocumentTrainingComplete": "ğŸ“„ğŸ“",  # Document training completed
    "DocumentPairBuilderComplete": "ğŸ“‘âœ…",  # Document pairs built
    "DocumentMRQTrainerEpoch": "ğŸ“ŠğŸ‹ï¸",  # Document MRQ epoch
    "DocumentMRQTrainingStart": "ğŸš€ğŸ“Š",  # Document MRQ training start
    "DocumentTrainingProgress": "ğŸ“ˆğŸ”„",  # Training progress
    "DocumentMRQTrainDimension": "ğŸ§©ğŸ“Š",  # Dimension training
    "DocumentPairBuilderProgress": "ğŸ“ŠğŸ“‘",  # Pair building progress
    "SVMInferenceInitialized": "ğŸ“ŠğŸ¤–",  # SVM inference agent initialized
    "LoadingSVMModel": "ğŸ“¥ğŸ“Š",  # Loading SVM model
    "SVMInferenceCompleted": "ğŸ“Šâœ…",  # SVM inference completed
    "EBTBufferCreated": "ğŸ§ªğŸ“¦",  # EBT buffer created
    "EBTTrainerEpoch": "ğŸ‹ï¸ğŸ§ª",  # EBT training epoch
    "TrainingCompleted": "ğŸğŸ“",  # Training completed
    "MRQTrainingEpoch": "ğŸ‹ï¸ğŸ§ ",  # MRQ training epoch
    "MRQEarlyStopping": "âœ¨ğŸ‹ï¸",  # MRQ early stopping
    "MRQTrainerInitialized": "ğŸ§ ğŸ¤–",  # MRQ trainer initialized
    "NoSamplesFound": "ğŸš«ğŸš«",  # No samples found for training
    "SICQLTrainingEpoch": "ğŸ‹ï¸ğŸ“Š",  # SICQL training epoch
    "SICQLTrainingComplete": "ğŸ“ğŸ“Š",  # SICQL training completed
}

# =================
# HYPOTHESIS WORKFLOW
# =================
HYPOTHESIS_OPS = {
    "GoalCreated": "ğŸ¯âœ¨",  # Goal created
    "GoalDomainAssigned": "ğŸ¯ğŸ·ï¸",  # Goal domain assigned
    "GeneratedHypotheses": "ğŸ’¡âœ¨",  # Hypotheses generated
    "HypothesisStored": "ğŸ’¾ğŸ’¡",  # Hypothesis stored
    "HypothesisInserted": "ğŸ“¥ğŸ’¡",  # Hypothesis inserted
    "HypothesisStoreFailed": "âŒğŸ’¡",  # Hypothesis store failed
    "EvolvingTopHypotheses": "ğŸ”„ğŸ’¡",  # Hypotheses evolving
    "EvolvedHypotheses": "ğŸŒ±ğŸ’¡",  # Hypotheses evolved
    "GraftingPair": "ğŸŒ¿â•",  # Hypothesis grafting
    "EditGenerated": "âœï¸",  # Hypothesis edit
    "SimilarHypothesesFound": "ğŸ”ğŸ’¡",  # Similar hypotheses found
    "NoHypothesesInContext": "ğŸš«ğŸ’¡",  # No hypotheses found
    "SharpenedHypothesisSaved": "ğŸ’ğŸ’¾",  # Sharpened hypothesis saved
}

# =================
# PROMPT OPERATIONS
# =================
PROMPTS = {
    "PromptLoaded": "ğŸ“„âœ…",  # Prompt loaded
    "PromptStored": "ğŸ’¾ğŸ“„",  # Prompt stored
    "PromptExecuted": "ğŸ’¬â–¶ï¸",  # Prompt executed
    "PromptFileLoading": "ğŸ“„ğŸ”„",  # Prompt file loading
    "PromptFileLoaded": "ğŸ“„âœ…",  # Prompt file loaded
    "CoTGenerated": "â›“ï¸ğŸ’­",  # Chain-of-Thought generated
    "LLMCacheHit": "ğŸ’¾âš¡",  # LLM cache hit
}

# =================
# RESEARCH & DATA
# =================
RESEARCH = {
    "ArxivSearchStart": "ğŸ”ğŸ“š",  # Arxiv search started
    "ArxivSearchComplete": "âœ…ğŸ“š",  # Arxiv search completed
    "ArxivQueryFilters": "âš™ï¸ğŸ”",  # Arxiv filters applied
    "DocumentsToJudge": "ğŸ“„âš–ï¸",  # Documents to judge
    "DocumentsFiltered": "ğŸ“‘ğŸ”",  # Documents filtered
    "LiteratureSearchCompleted": "âœ…ğŸ“š",  # Literature search completed
    "LiteratureSearchSkipped": "â­ï¸ğŸ“š",  # Literature search skipped
    "SearchingWeb": "ğŸŒğŸ”",  # Web search in progress
    "SearchResult": "ğŸ”ğŸ“„",  # Search result found
    "NoResultsFromWebSearch": "ğŸŒğŸš«",  # No search results
    "DocumentProfileFailed": "ğŸ“„âŒ",  # Document profile failed
    "DocumentsSearched": "ğŸ“„ğŸ”",  # Documents searched
    "SurveyAgentSkipped": "â­ï¸ğŸ“‹",  # Survey skipped
}

# ===================
# DEBUG & DIAGNOSTICS
# ===================
DEBUGGING = {
    "debug": "ğŸ",  # Debug message
    "NodeDebug": "ğŸŒ²ğŸ”",  # Node debugging
    "NodeSummary": "ğŸŒ²ğŸ“",  # Node summary
    "StageContext": "ğŸ”§ğŸ“‹",  # Stage context
    "TrimmingSection": "âœ‚ï¸",  # Section trimming
    "ContextAfterStage": "ğŸ—ƒï¸â¡ï¸",  # Post-stage context
    "ClassificationStarted": "ğŸ·ï¸â–¶ï¸",  # Classification started
    "ClassificationCompleted": "ğŸ·ï¸âœ…",  # Classification completed
}

# ======================
# ERROR & WARNING STATES
# ======================
ERROR_STATES = {
    "DocumentLoadFailed": "âš ï¸ğŸ“„",  # Document load failed
    "LiteratureQueryFailed": "âŒğŸ“š",  # Literature query failed
    "PromptLoadFailed": "âŒğŸ“",  # Prompt load failed
    "PromptParseFailed": "âŒğŸ“",  # Prompt parse failed
    "PromptEvaluationFailed": "âŒğŸ“",  # Prompt evaluation failed
    "TrainingError": "âŒğŸ‹ï¸",  # Training error
    "PreferencePairSaveError": "âŒğŸ’¾",  # Preference save error
    "RefinerError": "âŒğŸ”„",  # Refiner error
    "DocumentMRQModelMissing": "âŒğŸ§ ",  # MRQ model missing
    "DocumentMRQTunerMissing": "âŒğŸ”§",  # MRQ tuner missing
    "TunedPromptGenerationFailed": "âŒğŸ”„ğŸ“",  # Tuned prompt failed
    "InvalidRuleMutation": "âŒğŸ§¬",  # Invalid rule mutation
    "DocumentFilterSkipped": "â­ï¸ğŸ“„",  # Document filter skipped
}

# =============
# MODEL OPS
# =============
MODELS = {
    "EpistemicPlanHRMScorerModelLoaded": "ğŸª¸ğŸ§ ğŸ“¥",  # Epistemic Plan HRM scorer model loaded

    "SVMModelSaved": "ğŸ’¾ğŸ§®ğŸ“Š",  # SVM model saved
    "SVMModelLoaded": "ğŸ“¥ğŸ§®ğŸ“Š",  # SVM model load
    "SVMModelTrainingStarted": "ğŸ‹ï¸ğŸ§®âš–ï¸",
    "SVMTrainingStarted": "ğŸ‹ï¸ğŸ“Š",
    "EBTModelLoaded": "ğŸ“¥ğŸ§®ğŸ§ª",  # EBT model loaded
    "DocumentEBTModelSaved": "ğŸ’¾ğŸ§®âœ…",  # Model saved after training
    "DocumentEBTTrainingStart": "ğŸ§ªâ–¶ï¸",  # Training started for a dimension
    "DocumentEBTEpoch": "ğŸ“ŠğŸ”",  # Epoch completed during training
}

# =============
# ETHICS & REVIEWS
# =============
SPECIAL = {
    "PlanTraceCreated": "ğŸ“„ğŸ“",  # Plan trace created
    "PlanTraceScorerInitialized": "ğŸ“ŠğŸ¤–ğŸª¸",  # Plan trace scorer initialized
    "PlanTraceMonitorInitialized": "ğŸ“ŠğŸ¤–ğŸª¸",  # Plan trace monitor initialized
    "GILDProcessTraceStarted": "ğŸ“Šâ–¶ï¸",  # GILD process trace started
    "SICQLAdvantageExtracted": "ğŸ“ŠğŸ“ˆ",  # SICQL advantage extracted
    "SICQLAdvantageWarning": "âš ï¸ğŸ“Š",  # SICQL advantage warning
    "GILDDataPreparationCompleted": "ğŸ“Šâœ…",  # GILD data preparation completed
      
    "SQLQuery": "ğŸ’¾ğŸ”",  # SQL query executed
    "EthicsReviewsGenerated": "âš–ï¸ğŸ§¾",  # Ethics reviews generated
    "EarlyStopping": "âœ…â±ï¸",  # Early stopping triggered
}

# Combine all categories into a single dictionary
EVENT_ICONS = {
    **SYSTEM_INIT,
    **AGENT_EVENTS,
    **KNOWLEDGE_OPS,
    **PIPELINE_FLOW,
    **SCORING,
    **REASONING,
    **TRAINING,
    **HYPOTHESIS_OPS,
    **PROMPTS,
    **RESEARCH,
    **DEBUGGING,
    **ERROR_STATES,
    **MODELS,
    **SPECIAL,
}