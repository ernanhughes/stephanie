# co_ai/logs/json_logger.py
import json
from datetime import datetime, timezone
from pathlib import Path


class JSONLogger:
    EVENT_ICONS = {
        "PipelineStart": "ğŸ”¬",             # Start of pipeline execution
        "PipelineSuccess": "âœ…",           # Pipeline completed successfully
        "PipelineError": "âŒ",             # Pipeline encountered an error
        "PipelineStageStart": "ğŸš€",        # A specific stage in the pipeline is starting
        "PipelineStageEnd": "ğŸ",          # A specific stage has completed
        "PipelineStageSkipped": "â­ï¸",      # A stage was skipped (e.g., disabled)
        "PipelineIterationStart": "ğŸ”„",    # Start of a loop iteration
        "PipelineIterationEnd": "ğŸ”š",      # End of a loop iteration
        "IterationStart": "ğŸ”„",            # Alias for per-agent iteration
        "IterationEnd": "ğŸ”š",

        # Generation phase
        "GenerationAgent": "ğŸ§ª",           # The generation agent runs
        "GeneratedHypotheses": "ğŸ’¡",       # Output of generation (different from the agent)

        # Prompt handling
        "PromptLogged": "ğŸ§¾",              # Log/save a prompt (ğŸ“œ also works well)
        
        # Review phase
        "ReflectionAgent": "ğŸª",           # The reflection agent runs
        "ReviewStored": "ğŸ’¬",              # Review feedback stored (better match than ğŸ“¥)
        "ReflectedHypotheses": "ğŸ”",       # After reflection logic

        # Ranking
        "RankingAgent": "ğŸ†",              # The ranking agent run s
        "RankedHypotheses": "ğŸ…",          # After ranking

        # Evolution phase
        "EvolutionAgent": "ğŸ§¬",
        "EvolvingTopHypotheses": "ğŸ”„",
        "EvolvedHypotheses": "ğŸŒ±",         # Represents new/modified hypotheses
        "GraftingPair": "ğŸŒ¿",              # Represents a grafting pair

        # Meta review
        "MetaReviewAgent": "ğŸ§ ",
        "MetaReviewSummary": "ğŸ“˜",         # Summary output
        "SummaryLogged": "ğŸ“",

        # Hypothesis storage
        "HypothesisStored": "ğŸ“¥",          # Store raw hypothesis

        # Other
        "Prompt": "ğŸ“œ",                  # General prompt
        "debug": "ğŸ"
    }
     
    def __init__(self, log_path="logs/pipeline_log.jsonl"):
        self.log_path = Path(log_path)
        self.log_path.parent.mkdir(parents=True, exist_ok=True)

    def log(self, event_type: str, data: dict):
        icon = self.EVENT_ICONS.get(event_type, "ğŸ“¦")  # Default icon
        print(f"{icon} Logging event: {event_type} with data: {str(data)[:100]}")
        try:
            log_entry = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "event_type": event_type,
                "data": data
            }
            with open(self.log_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(log_entry, default=str) + "\n")
        except TypeError as e:
            print(f"[Logger] Skipping non-serializable log: {e}")
            print(f"[Logger] Problematic record: {log_entry}")

