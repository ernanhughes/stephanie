import json
from datetime import datetime, timezone
from pathlib import Path


class JSONLogger:
    DEFAULT_ICON = "ğŸ“¦"

    EVENT_ICONS = {
        # General System & Supervisor
        "SupervisorInit": "ğŸ§‘â€ğŸ«",
        "AgentInitialized": "ğŸ› ï¸",
        "StoreRegistered": "âœ…",
        "ContextSaved": "ğŸ’¾",
        "ContextLoaded": "ğŸ“‚",
        "ContextYAMLDumpSaved": "ğŸ“„",
        "ContextAfterStage": "ğŸ—ƒï¸",
        "debug": "ğŸ",

        # Pipeline execution
        "PipelineStart": "ğŸ”¬",
        "PipelineSuccess": "âœ…",
        "PipelineError": "âŒ",
        "PipelineStageStart": "ğŸš€",
        "PipelineStageEnd": "ğŸ",
        "PipelineStageSkipped": "â­ï¸",
        "PipelineIterationStart": "ğŸ”„",
        "PipelineIterationEnd": "ğŸ”š",
        "IterationStart": "ğŸ”„",
        "IterationEnd": "ğŸ”š",

        # Generation phase
        "GenerationStart": "âœ¨",
        "GenerationAgent": "ğŸ§ª",
        "GeneratedHypotheses": "ğŸ’¡",

        # Ranking phase
        "RankingAgent": "ğŸ†",
        "RankedHypotheses": "ğŸ…",
        "RankingStored": "ğŸ—ƒï¸",
        "RankingUpdated": "ğŸ”",

        # Review and reflection
        "ReviewAgent": "ğŸ§‘â€âš–ï¸",
        "ReviewStored": "ğŸ’¬",
        "MetaReviewAgent": "ğŸ§ ",
        "MetaReviewSummary": "ğŸ“˜",
        "MetaReviewInput": "ğŸ“‰",
        "NotEnoughHypothesesForRanking": "âš ï¸",
        "GeneratedReviews": "ğŸ§¾",
        "RawMetaReviewOutput": "ğŸ“œ",
        "SummaryLogged": "ğŸ“",
        "ReflectionAgent": "ğŸª",
        "ReflectionStart": "ğŸ¤”",
        "ReflectionStored": "ğŸ’¾",

        # Evolution phase
        "EvolutionAgent": "ğŸ§¬",
        "EvolvingTopHypotheses": "ğŸ”„",
        "EvolvedHypotheses": "ğŸŒ±",
        "EvolvedParsedHypotheses": "ğŸ§¬",
        "GraftingPair": "ğŸŒ¿",
        "EvolutionCompleted": "ğŸ¦¾",
        "EvolutionError": "âš ï¸",

        # Literature & research
        "LiteratureAgentInit": "ğŸ“š",
        "LiteratureSearchSkipped": "â­ï¸",
        "LiteratureQueryFailed": "â“",
        "NoResultsFromWebSearch": "ğŸš«",
        "DatabaseHypothesesMatched": "ğŸ”",
        "ProximityGraphComputed": "ğŸ—ºï¸",

        # Prompt handling
        "Prompt": "ğŸ“œ",
        "PromptLogged": "ğŸ§¾",
        "ReportGenerated": "ğŸ“Š",
    }

    def __init__(self, log_path="logs/pipeline_log.jsonl"):
        self.log_path = Path(log_path)
        self.log_path.parent.mkdir(parents=True, exist_ok=True)

    def log(self, event_type: str, data: dict):
        icon = self.EVENT_ICONS.get(event_type, self.DEFAULT_ICON)
        print(f"{icon} [{event_type}] {str(data)[:100]}")

        log_entry = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "event_type": event_type,
            "data": data,
        }

        try:
            with self.log_path.open("a", encoding="utf-8") as f:
                json.dump(log_entry, f, default=str)
                f.write("\n")
        except (TypeError, ValueError) as e:
            print("âŒ [Logger] Failed to serialize log entry.")
            print(f"ğŸ› ï¸  Event Type: {event_type}")
            print(f"ğŸªµ  Error: {e}")
            print(f"ğŸ§±  Data: {repr(data)[:200]}")
